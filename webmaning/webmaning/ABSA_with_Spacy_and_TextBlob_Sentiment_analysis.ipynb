{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "  'The food we had yesterday was delicious',\n",
    "  'My time in Italy was very enjoyable',\n",
    "  'I found the meal to be tasty',\n",
    "  'The internet was slow.',\n",
    "  'Our experience was suboptimal'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nous allons faire un split sur nos phrase de telle façcon à obtenir l'aspect (ex: food) et son expression (ex: delicious)\n",
    "\n",
    "Pour chaque jeton à l'intérieur de nos phrases, nous pouvons voir la dépendance grâce à l'analyse des dépendances de spacy et aux POS (Part-Of-Speech)tags\n",
    "https://spacy.io/usage/linguistic-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The det food NOUN DET []\n",
      "food nsubj was AUX NOUN [The, had]\n",
      "we nsubj had VERB PRON []\n",
      "had relcl food NOUN VERB [we, yesterday]\n",
      "yesterday npadvmod had VERB NOUN []\n",
      "was ROOT was AUX AUX [food, delicious]\n",
      "delicious acomp was AUX ADJ []\n",
      "My poss time NOUN PRON []\n",
      "time nsubj was AUX NOUN [My, in]\n",
      "in prep time NOUN ADP [Italy]\n",
      "Italy pobj in ADP PROPN []\n",
      "was ROOT was AUX AUX [time, enjoyable]\n",
      "very advmod enjoyable ADJ ADV []\n",
      "enjoyable acomp was AUX ADJ [very]\n",
      "I nsubj found VERB PRON []\n",
      "found ROOT found VERB VERB [I, be]\n",
      "the det meal NOUN DET []\n",
      "meal nsubj be AUX NOUN [the]\n",
      "to aux be AUX PART []\n",
      "be ccomp found VERB AUX [meal, to, tasty]\n",
      "tasty acomp be AUX ADJ []\n",
      "The det internet NOUN DET []\n",
      "internet nsubj was AUX NOUN [The]\n",
      "was ROOT was AUX AUX [internet, slow, .]\n",
      "slow acomp was AUX ADJ []\n",
      ". punct was AUX PUNCT []\n",
      "Our poss experience NOUN PRON []\n",
      "experience nsubj was AUX NOUN [Our]\n",
      "was ROOT was AUX AUX [experience, suboptimal]\n",
      "suboptimal acomp was AUX ADJ []\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "  doc = nlp(sentence)\n",
    "  for token in doc:\n",
    "    print(token.text, token.dep_, token.head.text, token.head.pos_,token.pos_,[child for child in token.children])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ci-dessous un exemple de visualisation de dépendance dans une phrase:\n",
    "\n",
    "https://spacy.io/usage/visualizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\spacy\\displacy\\__init__.py:103: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  warnings.warn(Warnings.W011)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The food we had \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    yesterday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " was delicious</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "\n",
    "doc = nlp(\"The food we had yesterday was delicious\")\n",
    "displacy.serve(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant les caractéristiques linguistique et notemment les POS, nous allons extraire les adjectives comme expression de sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The food we had yesterday was delicious\n",
      "delicious\n",
      "My time in Italy was very enjoyable\n",
      "enjoyable\n",
      "I found the meal to be tasty\n",
      "tasty\n",
      "The internet was slow.\n",
      "slow\n",
      "Our experience was suboptimal\n",
      "suboptimal\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "  doc = nlp(sentence)\n",
    "  descriptive_term = ''\n",
    "  for token in doc:\n",
    "    if token.pos_ == 'ADJ':\n",
    "      descriptive_term = token\n",
    "  print(sentence)\n",
    "  print(descriptive_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vous pouvez le remarquer, ce qui manque ce sont intensificateurs comme \"very\" (nous allons éviter les adverbes). nous allons les extraires en utilisant la propriété children.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The food we had yesterday was delicious\n",
      "delicious\n",
      "My time in Italy was very enjoyable\n",
      "very enjoyable\n",
      "I found the meal to be tasty\n",
      "tasty\n",
      "The internet was slow.\n",
      "slow\n",
      "Our experience was suboptimal\n",
      "suboptimal\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "  doc = nlp(sentence)\n",
    "  descriptive_term = ''\n",
    "  for token in doc:\n",
    "    if token.pos_ == 'ADJ':\n",
    "      prepend = ''\n",
    "      for child in token.children:\n",
    "        if child.pos_ != 'ADV':\n",
    "          continue\n",
    "        prepend += child.text + ' '\n",
    "      descriptive_term = prepend + token.text\n",
    "  print(sentence)\n",
    "  print(descriptive_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons mettre ça dans une liste de dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'aspect': 'food', 'description': 'delicious'}, {'aspect': 'time', 'description': 'very enjoyable'}, {'aspect': 'meal', 'description': 'tasty'}, {'aspect': 'internet', 'description': 'slow'}, {'aspect': 'experience', 'description': 'suboptimal'}]\n"
     ]
    }
   ],
   "source": [
    "aspects = []\n",
    "for sentence in sentences:\n",
    "  doc = nlp(sentence)\n",
    "  descriptive_term = ''\n",
    "  target = ''\n",
    "  for token in doc:\n",
    "    if token.dep_ == 'nsubj' and token.pos_ == 'NOUN':\n",
    "      target = token.text\n",
    "    if token.pos_ == 'ADJ':\n",
    "      prepend = ''\n",
    "      for child in token.children:\n",
    "        if child.pos_ != 'ADV':\n",
    "          continue\n",
    "        prepend += child.text + ' '\n",
    "      descriptive_term = prepend + token.text  \n",
    "    \n",
    "  aspects.append({'aspect': target,'description': descriptive_term})\n",
    "print(aspects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utilisation de TextBlob pour l'extraction de sentiment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob est une bibliothèque qui propose une analyse des sentiments prête à l'emploi. Il a une approche par sac de mots, ce qui signifie qu'il a une liste de mots tels que «bon», «mauvais» et «excellent» qui ont un score de sentiment qui leur est attaché. Il est également capable de sélectionner des modificateurs (tels que «not») et des intensificateurs (tels que «very») qui affectent le score de sentiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'aspect': 'food', 'description': 'delicious', 'sentiment': Sentiment(polarity=1.0, subjectivity=1.0)}, {'aspect': 'time', 'description': 'very enjoyable', 'sentiment': Sentiment(polarity=0.65, subjectivity=0.78)}, {'aspect': 'meal', 'description': 'tasty', 'sentiment': Sentiment(polarity=0.0, subjectivity=0.0)}, {'aspect': 'internet', 'description': 'slow', 'sentiment': Sentiment(polarity=-0.30000000000000004, subjectivity=0.39999999999999997)}, {'aspect': 'experience', 'description': 'suboptimal', 'sentiment': Sentiment(polarity=0.0, subjectivity=0.0)}]\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "for aspect in aspects:\n",
    "  aspect['sentiment'] = TextBlob(aspect['description']).sentiment\n",
    "print(aspects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en regardant les résultats nous pouvons remarquer que les adjectifs \"tasty\" et \"suboptimal\" sont considéré comme neutres. Il semble qu’ils ne font pas partie du dictionnaire de TextBlob et qu’ils ne sont donc pas repris. \n",
    "\n",
    "TextBlob nous permet d'entraîner un NaiveBayesClassifier à l'aide d'une syntaxe très simple et facile à comprendre pour tout le monde, que nous utiliserons pour améliorer notre analyse des sentiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delicious food.\n",
      "positive\n",
      "Very Slow internet.\n",
      "negative\n",
      "Suboptimal experience.\n",
      "negative\n",
      "Enjoyable food.\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "# We train the NaivesBayesClassifier\n",
    "train = [\n",
    "  ('Slow internet.', 'negative'),\n",
    "  ('Delicious food', 'positive'),\n",
    "  ('Suboptimal experience', 'negative'),\n",
    "  ('Very enjoyable time', 'positive'),\n",
    "  ('delicious food.', 'neg')\n",
    "]\n",
    "cl = NaiveBayesClassifier(train)# And then we try to classify some sample sentences.\n",
    "blob = TextBlob(\"Delicious food. Very Slow internet. Suboptimal experience. Enjoyable food.\", classifier=cl)\n",
    "for s in blob.sentences:\n",
    "  print(s)\n",
    "  print(s.classify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant refaire notre classification en utilisant le modèle entrainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'aspect': 'food', 'description': 'delicious', 'sentiment': 'neg'}, {'aspect': 'time', 'description': 'very enjoyable', 'sentiment': 'positive'}, {'aspect': 'meal', 'description': 'tasty', 'sentiment': 'negative'}, {'aspect': 'internet', 'description': 'slow', 'sentiment': 'negative'}, {'aspect': 'experience', 'description': 'suboptimal', 'sentiment': 'negative'}]\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "for aspect in aspects:\n",
    "  blob = TextBlob(aspect['description'], classifier=cl)  \n",
    "  aspect['sentiment'] = blob.classify()\n",
    "print(aspects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajouter une phrase 'life is good','The match was fantastic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "  'The food we had yesterday was delicious',\n",
    "  'My time in Italy was very enjoyable',\n",
    "  'I found the meal to be tasty',\n",
    "  'The internet was slow.',\n",
    "  'Our experience was suboptimal',\n",
    "  'life is good',\n",
    " 'The match was fantastic'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crée un dictionnaire avec les noms et leurs adjectifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'aspect': 'food', 'description': 'delicious'}, {'aspect': 'time', 'description': 'very enjoyable'}, {'aspect': 'meal', 'description': 'tasty'}, {'aspect': 'internet', 'description': 'slow'}, {'aspect': 'experience', 'description': 'suboptimal'}, {'aspect': 'life', 'description': 'good'}, {'aspect': 'match', 'description': 'fantastic'}]\n"
     ]
    }
   ],
   "source": [
    "aspects = []\n",
    "for sentence in sentences:\n",
    "  doc = nlp(sentence)\n",
    "  descriptive_term = ''\n",
    "  target = ''\n",
    "  for token in doc:\n",
    "    if token.dep_ == 'nsubj' and token.pos_ == 'NOUN':\n",
    "      target = token.text\n",
    "    if token.pos_ == 'ADJ':\n",
    "      prepend = ''\n",
    "      for child in token.children:\n",
    "        if child.pos_ != 'ADV':\n",
    "          continue\n",
    "        prepend += child.text + ' '\n",
    "      descriptive_term = prepend + token.text  \n",
    "    \n",
    "  aspects.append({'aspect': target,'description': descriptive_term})\n",
    "print(aspects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "utiliser TexTBlob pour extraire la polarity de chaque adjectif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'aspect': 'food', 'description': 'delicious', 'sentiment': Sentiment(polarity=1.0, subjectivity=1.0)}, {'aspect': 'time', 'description': 'very enjoyable', 'sentiment': Sentiment(polarity=0.65, subjectivity=0.78)}, {'aspect': 'meal', 'description': 'tasty', 'sentiment': Sentiment(polarity=0.0, subjectivity=0.0)}, {'aspect': 'internet', 'description': 'slow', 'sentiment': Sentiment(polarity=-0.30000000000000004, subjectivity=0.39999999999999997)}, {'aspect': 'experience', 'description': 'suboptimal', 'sentiment': Sentiment(polarity=0.0, subjectivity=0.0)}, {'aspect': 'life', 'description': 'good', 'sentiment': Sentiment(polarity=0.7, subjectivity=0.6000000000000001)}, {'aspect': 'match', 'description': 'fantastic', 'sentiment': Sentiment(polarity=0.4, subjectivity=0.9)}]\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "for aspect in aspects:\n",
    "  aspect['sentiment'] = TextBlob(aspect['description']).sentiment\n",
    "print(aspects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraîner un NaivesBayesClassifier avec des phrase d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delicious food.\n",
      "positive\n",
      "Very Slow internet.\n",
      "negative\n",
      "Suboptimal experience.\n",
      "negative\n",
      "Enjoyable food.\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "# We train the NaivesBayesClassifier\n",
    "train = [\n",
    "  ('Slow internet.', 'negative'),\n",
    "  ('Delicious food', 'positive'),\n",
    "  ('Suboptimal experience', 'negative'),\n",
    "  ('Very enjoyable time', 'positive'),\n",
    "  ('delicious food.', 'neg')\n",
    "]\n",
    "cl = NaiveBayesClassifier(train)# And then we try to classify some sample sentences.\n",
    "blob = TextBlob(\"Delicious food. Very Slow internet. Suboptimal experience. Enjoyable food.\", classifier=cl)\n",
    "for s in blob.sentences:\n",
    "  print(s)\n",
    "  print(s.classify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tester notre modèle avec les phrase de départ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'aspect': 'food', 'description': 'delicious', 'sentiment': 'neg'}, {'aspect': 'time', 'description': 'very enjoyable', 'sentiment': 'positive'}, {'aspect': 'meal', 'description': 'tasty', 'sentiment': 'negative'}, {'aspect': 'internet', 'description': 'slow', 'sentiment': 'negative'}, {'aspect': 'experience', 'description': 'suboptimal', 'sentiment': 'negative'}, {'aspect': 'life', 'description': 'good', 'sentiment': 'negative'}, {'aspect': 'match', 'description': 'fantastic', 'sentiment': 'negative'}]\n"
     ]
    }
   ],
   "source": [
    "for aspect in aspects:\n",
    "  blob = TextBlob(aspect['description'], classifier=cl)  \n",
    "  aspect['sentiment'] = blob.classify()\n",
    "print(aspects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que le modèle n'a pas bien classifier la nouvelle phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va essayer d'ajouter des phrase d'entraînement, et reentraîner le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delicious food.\n",
      "positive\n",
      "Very Slow internet.\n",
      "negative\n",
      "Suboptimal experience.\n",
      "negative\n",
      "Enjoyable food.\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "# We train the NaivesBayesClassifier\n",
    "train = [\n",
    "  ('Slow internet.', 'negative'),\n",
    "  ('Delicious food', 'positive'),\n",
    "  ('Suboptimal experience', 'negative'),\n",
    "  ('Very enjoyable time', 'positive'),\n",
    "  ('delicious food.', 'neg'),\n",
    "  ('fast computer.', 'positive')\n",
    "]\n",
    "cl = NaiveBayesClassifier(train)# And then we try to classify some sample sentences.\n",
    "blob = TextBlob(\"Delicious food. Very Slow internet. Suboptimal experience. Enjoyable food.\", classifier=cl)\n",
    "for s in blob.sentences:\n",
    "  print(s)\n",
    "  print(s.classify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tester le nouveau modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'aspect': 'food', 'description': 'delicious', 'sentiment': 'neg'}, {'aspect': 'time', 'description': 'very enjoyable', 'sentiment': 'positive'}, {'aspect': 'meal', 'description': 'tasty', 'sentiment': 'positive'}, {'aspect': 'internet', 'description': 'slow', 'sentiment': 'positive'}, {'aspect': 'experience', 'description': 'suboptimal', 'sentiment': 'positive'}, {'aspect': 'life', 'description': 'good', 'sentiment': 'positive'}, {'aspect': 'match', 'description': 'fantastic', 'sentiment': 'positive'}]\n"
     ]
    }
   ],
   "source": [
    "for aspect in aspects:\n",
    "  blob = TextBlob(aspect['description'], classifier=cl)  \n",
    "  aspect['sentiment'] = blob.classify()\n",
    "print(aspects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### la phrase est bien classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
